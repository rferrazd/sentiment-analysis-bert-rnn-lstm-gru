{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "45e43699",
   "metadata": {},
   "source": [
    "# Comparative Analysis: Sentiment Analysis Using\n",
    "BERT, LSTM, GRU, and RNN\n",
    "\n",
    "## Objective\n",
    "Perform sentiment analysis on the given dataset using multiple deep learning models: BERT, LSTM, GRU, and RNN, and conduct a comparative analysis based on their performance metrics.\n",
    "Dataset\n",
    "## Implementation Plan\n",
    "1. Data Preprocessing\n",
    "    ● Load the Dataset: Import the CSV file and extract the relevant columns (polarity,\n",
    "    text).\n",
    "    ● Clean the Text: Remove URLs, special characters, numbers, and extra spaces. Convert\n",
    "    text to lowercase.\n",
    "    ● Tokenization: Split the text into individual tokens using a tokenizer suitable for each\n",
    "    model (e.g., Word2Vec for RNN-based models, BERT tokenizer for BERT).\n",
    "    ● Class Mapping: Map sentiment labels:\n",
    "        ○ 0 → Negative\n",
    "        ○ 2 → Neutral\n",
    "        ○ 4 → Positive\n",
    "    ● Train-Test Split: Divide the data into training, validation, and test sets.\n",
    "2. Feature Engineering\n",
    "    ● BERT Tokenization:\n",
    "        ○ Use a pre-trained BERT tokenizer to convert the text into input IDs, attention\n",
    "        masks, and token type IDs.\n",
    "    ● Embedding for RNN-based Models:\n",
    "        ○ Generate word embeddings using GloVe or Word2Vec.\n",
    "        ○ Pad sequences to a fixed length for uniformity.\n",
    "3. Model Implementation\n",
    "    ● BERT:\n",
    "        ○ Use a pre-trained BERT model from the Hugging Face library.\n",
    "        ○ Add a classification head (e.g., a dense layer with softmax activation) to fine-tune\n",
    "        the model.\n",
    "    ● LSTM:\n",
    "        ○ Use a sequential model with embedding, LSTM layers, and a dense output layer.\n",
    "    ● GRU:\n",
    "        ○ Similar to LSTM but replace LSTM layers with GRU layers for comparison.\n",
    "    ● RNN:\n",
    "        ○ Use simple RNN layers instead of LSTM/GRU for baseline comparison.\n",
    "4. Evaluation Metrics\n",
    "    ● Accuracy: Overall percentage of correct predictions.\n",
    "    ● Precision, Recall, F1-Score: Evaluate per class (negative, neutral, positive).\n",
    "    ● Confusion Matrix: Show performance across all classes.\n",
    "    ● ROC-AUC Score: Measure the ability of the model to distinguish between classes.\n",
    "5. Comparative Analysis\n",
    "    ● Compare the models on:\n",
    "        ○ Performance metrics (accuracy, precision, recall, F1-score).\n",
    "        ○ Computational requirements (training time, memory usage).\n",
    "        ○ Complexity of implementation.\n",
    "    ● Generate visualizations:\n",
    "        ○ Bar chart comparing F1-scores for all models.\n",
    "        ○ Line plot showing training/validation loss and accuracy over epochs.\n",
    "        ○ Confusion matrix heatmaps for each model.\n",
    "6. Expected Outcome\n",
    "    ● BERT: Likely to outperform RNN-based models due to its pre-trained contextual\n",
    "    embeddings and transformer architecture.\n",
    "    ● LSTM/GRU: Expected to perform better than simple RNN due to their ability to handle\n",
    "    long-term dependencies and avoid vanishing gradient problems.\n",
    "    ● RNN: May provide a baseline but is likely to underperform compared to other models.\n",
    "7. Deliverables\n",
    "    ● Code implementation for each model in Python (using libraries like TensorFlow, PyTorch,\n",
    "    Hugging Face).\n",
    "    ● Comparative analysis report with:\n",
    "    ○ Metric tables\n",
    "    ○ Charts and graphs\n",
    "    ○ Insights on model performance.\n",
    "    ● Recommendations on the best model for deployment based on trade-offs between\n",
    "    performance and resource usage."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c35792e8",
   "metadata": {},
   "source": [
    "## Inspect the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "872fadb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "import re\n",
    "# Set seed\n",
    "np.random.seed(42)\n",
    "\n",
    "test_df = pd.read_csv('sentiment-analysis-dataset/testdata.manual.2009.06.14.csv', encoding='latin1')\n",
    "train_df = pd.read_csv('sentiment-analysis-dataset/training.1600000.processed.noemoticon.csv', encoding='latin1')\n",
    "# Strip extra white spaces from train_df column names (tweet data fields)\n",
    "train_df.columns = train_df.columns.str.strip()\n",
    "print(\"Shape: \", train_df.shape)\n",
    "print(\"Columns: \", train_df.columns)\n",
    "print(\"Tweet polarity distribution (%):\\n\", train_df['polarity of tweet'].value_counts(normalize=True) * 100)\n",
    "print()\n",
    "train_df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f88d543",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Test set columns: {test_df.columns}\")\n",
    "# Test_df is not in the expected, formated. Using train_df as the entire dataset.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8769c72f",
   "metadata": {},
   "source": [
    "## Clean the Text: Remove URLs, special characters, numbers, and extra spaces. Convert text to lowercase."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d9c4876",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Clean the Text: Remove URLs, special characters, numbers, and extra spaces. Convert text to lowercase.\n",
    "def clean_tweet(text: str):\n",
    "    # Remove URLs\n",
    "    text = re.sub(r\"http\\S+|www\\S+|https\\S+\", '', text, flags=re.MULTILINE)\n",
    "    # Remove usernames (@user)\n",
    "    text = re.sub(r'@\\w+', '', text)\n",
    "    # Remove special characters and numbers (except whitespace)\n",
    "    text = re.sub(r\"[^a-zA-Z\\s]\", \"\", text)\n",
    "    # Remove extra spaces\n",
    "    text = re.sub(r'\\s+', ' ', text)\n",
    "    # Convert to lowercase and strip leading/trailing whitespace\n",
    "    return text.lower().strip()\n",
    "\n",
    "# Apply cleaning function to the tweets\n",
    "clean_tweets = train_df['text of the tweet'].apply(clean_tweet)\n",
    "clean_df = train_df.copy()\n",
    "# Save the cleaned df\n",
    "clean_df['text of the tweet'] = clean_tweets\n",
    "clean_df.to_pickle('clean_df.pkl')\n",
    "clean_df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "030f0b56",
   "metadata": {},
   "source": [
    "# Splitting into Train, Test, and Val\n",
    "    - 10% test set\n",
    "    - 72% training set\n",
    "    - 18% validation set\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "267d7ecc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# OVERSAMPLING class 4:\n",
    "    # Tweet polarity distribution (%):\n",
    "    #  polarity of tweet\n",
    "    # 0    76.293855\n",
    "    # 4    23.706145\n",
    "df = clean_df.copy()\n",
    "\n",
    "# Define features and target\n",
    "X = df#['text of the tweet']\n",
    "y = df['polarity of tweet']\n",
    "\n",
    "# BALANCED SPLIT: Using OVERSAMPLING to preserve more data\n",
    "# This approach keeps ALL majority class samples and oversamples the minority class\n",
    "# Separate data by class\n",
    "class_0_mask = y == 0\n",
    "class_4_mask = y == 4\n",
    "\n",
    "X_class_0 = X[class_0_mask]\n",
    "y_class_0 = y[class_0_mask]\n",
    "X_class_4 = X[class_4_mask]\n",
    "y_class_4 = y[class_4_mask]\n",
    "\n",
    "print(f\"Original - Class 0 samples: {len(X_class_0)}\")\n",
    "print(f\"Original - Class 4 samples: {len(X_class_4)}\")\n",
    "\n",
    "# Use ALL samples from class 0 (majority class)\n",
    "# Oversample class 4 (minority class) to match class 0 size\n",
    "max_class_size = len(X_class_0)  # Use majority class size as target\n",
    "print(f\"\\nTarget size per class: {max_class_size} samples\")\n",
    "print(f\"Class 4 needs {max_class_size - len(X_class_4)} additional samples (oversampling)\\n\")\n",
    "\n",
    "\n",
    "# For class 0: Use all samples (no sampling needed - preserves all data!)\n",
    "X_class_0_balanced = X_class_0.copy()\n",
    "y_class_0_balanced = y_class_0.copy()\n",
    "\n",
    "# For class 4: Oversample to match class 0 size\n",
    "# Calculate how many additional samples we need\n",
    "additional_samples_needed = max_class_size - len(X_class_4)\n",
    "\n",
    "# Randomly sample WITH replacement from class 4 to create additional samples\n",
    "oversample_indices = np.random.choice(len(X_class_4), additional_samples_needed, replace=True)\n",
    "\n",
    "# Get the oversampled data\n",
    "X_class_4_oversampled = X_class_4.iloc[oversample_indices]\n",
    "y_class_4_oversampled = y_class_4.iloc[oversample_indices]\n",
    "\n",
    "# Combine original class 4 samples with oversampled ones\n",
    "X_class_4_balanced = pd.concat([X_class_4, X_class_4_oversampled], ignore_index=True)\n",
    "y_class_4_balanced = pd.concat([y_class_4, y_class_4_oversampled], ignore_index=True)\n",
    "\n",
    "print(f\"After oversampling:\")\n",
    "print(f\"  Class 0: {len(X_class_0_balanced)} samples (all original samples preserved)\")\n",
    "print(f\"  Class 4: {len(X_class_4_balanced)} samples ({len(X_class_4)} original + {additional_samples_needed} oversampled)\")\n",
    "print(f\"  Total: {len(X_class_0_balanced) + len(X_class_4_balanced)} samples\\n\")\n",
    "\n",
    "# Combine balanced classes\n",
    "X_balanced = pd.concat([X_class_0_balanced, X_class_4_balanced], ignore_index=True)\n",
    "y_balanced = pd.concat([y_class_0_balanced, y_class_4_balanced], ignore_index=True)\n",
    "\n",
    "# Shuffle the combined data\n",
    "shuffle_indices = np.random.permutation(len(X_balanced))\n",
    "X_balanced = X_balanced.iloc[shuffle_indices].reset_index(drop=True)\n",
    "y_balanced = y_balanced.iloc[shuffle_indices].reset_index(drop=True)\n",
    "\n",
    "# Now split the balanced data: First split to (train+val) and test (90% train+val, 20% test)\n",
    "X_trainval, X_test, y_trainval, y_test = train_test_split(\n",
    "    X_balanced, y_balanced, test_size=0.1, random_state=42, stratify=y_balanced\n",
    ")\n",
    "\n",
    "# Now split train+val into train and val (80% train, 20% val of the remaining)\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X_trainval, y_trainval, test_size=0.2, random_state=42, stratify=y_trainval\n",
    ")\n",
    "\n",
    "print(f\"Train set shape: {X_train.shape}\")\n",
    "print(f\"Val set shape:   {X_val.shape}\")\n",
    "print(f\"Test set shape:  {X_test.shape}\\n\")\n",
    "\n",
    "def print_class_balance(y, set_name=\"\"):\n",
    "    value_counts = y.value_counts()\n",
    "    percentage = value_counts / value_counts.sum() * 100\n",
    "    balance_df = pd.DataFrame({'count': value_counts, 'percentage': percentage.round(2)})\n",
    "    print(f\"{set_name} class balance:\\n{balance_df}\\n\")\n",
    "\n",
    "print_class_balance(y_train, \"Train\")\n",
    "print_class_balance(y_val, \"Val\")\n",
    "print_class_balance(y_test, \"Test\")\n",
    "\n",
    "# Save the datasets in .pkl files \n",
    "# train\n",
    "train = X_train.copy()\n",
    "train['polarity of tweet'] = y_train.values  # keep original column\n",
    "train['label'] = y_train.values         \n",
    "# val    \n",
    "val = X_val.copy()\n",
    "val['polarity of tweet'] = y_val.values\n",
    "val['label'] = y_val.values\n",
    "# test \n",
    "test = X_test.copy()\n",
    "test['polarity of tweet'] = y_test.values\n",
    "test['label'] = y_test.values\n",
    "\n",
    "train.to_pickle(\"train.pkl\")\n",
    "val.to_pickle(\"val.pkl\")\n",
    "test.to_pickle(\"test.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67ab068a",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3743c7e4",
   "metadata": {},
   "source": [
    "# Read pickle files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5d412480",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "clean_df shape: (1048572, 6)\n",
      "train shape: (1151993, 7)\n",
      "val shape: (287999, 7)\n",
      "test shape: (160000, 7)\n",
      "train columns: ['polarity of tweet', 'id of the tweet', 'date of the tweet', 'query', 'user', 'text of the tweet', 'label']\n",
      "val columns:   ['polarity of tweet', 'id of the tweet', 'date of the tweet', 'query', 'user', 'text of the tweet', 'label']\n",
      "test columns:  ['polarity of tweet', 'id of the tweet', 'date of the tweet', 'query', 'user', 'text of the tweet', 'label']\n",
      "✅ train, val, and test have the same columns.\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "# Load the pkl files\n",
    "with open(\"clean_df.pkl\", \"rb\") as f:\n",
    "    clean_df_loaded = pickle.load(f)\n",
    "with open(\"train.pkl\", \"rb\") as f:\n",
    "    train_loaded = pickle.load(f)\n",
    "with open(\"val.pkl\", \"rb\") as f:\n",
    "    val_loaded = pickle.load(f)\n",
    "with open(\"test.pkl\", \"rb\") as f:\n",
    "    test_loaded = pickle.load(f)\n",
    "\n",
    "# Print their shapes\n",
    "print(f\"clean_df shape: {clean_df_loaded.shape}\")\n",
    "print(f\"train shape: {train_loaded.shape}\")\n",
    "print(f\"val shape: {val_loaded.shape}\")\n",
    "print(f\"test shape: {test_loaded.shape}\")\n",
    "\n",
    "# Verify that train, val, and test have the same columns\n",
    "print(f\"train columns: {train_loaded.columns.tolist()}\")\n",
    "print(f\"val columns:   {val_loaded.columns.tolist()}\")\n",
    "print(f\"test columns:  {test_loaded.columns.tolist()}\")\n",
    "\n",
    "assert set(train_loaded.columns) == set(val_loaded.columns) == set(test_loaded.columns), \\\n",
    "    \"train, val, test files do not have the same columns!\"\n",
    "print(\"✅ train, val, and test have the same columns.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
