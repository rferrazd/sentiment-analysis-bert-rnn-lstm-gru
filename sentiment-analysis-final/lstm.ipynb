{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ba0fc5ed",
   "metadata": {},
   "source": [
    "# LSTM \n",
    "\n",
    "Implementation based on code from notebook: 1. Encoder-Decoder Seq2Seq.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dc8885c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np \n",
    "import torch \n",
    "from gensim.models import Word2Vec\n",
    "from torch.nn import functional as F\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "\n",
    "SEED = 42\n",
    "np.random.seed(SEED)\n",
    "\n",
    "# Load the datasets \n",
    "with open(\"train.pkl\", \"rb\") as f:\n",
    "    train = pickle.load(f)\n",
    "with open(\"val.pkl\", \"rb\") as f:\n",
    "    val = pickle.load(f)\n",
    "with open(\"test.pkl\", \"rb\") as f:\n",
    "    test = pickle.load(f)\n",
    "\n",
    "num_labels = train['label'].nunique()\n",
    "print(\"Number of labels: \", num_labels)\n",
    "labels = [label for i, label in enumerate(train['label'].value_counts().index)]\n",
    "labels\n",
    "label_0 = labels[1]\n",
    "label_4 = labels[0]\n",
    "print(f\"Label 0: {label_0} and label 4: {label_4}\")\n",
    "\n",
    "train.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c6944bc",
   "metadata": {},
   "source": [
    "# LSTM Encoder \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7d86429",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch\n",
    "class BiLSTM_Classifier(nn.Module):\n",
    "    \"\"\"\n",
    "    A Bidirectional LSTM-based module designed for sequence encoding\n",
    "    and subsequent sentiment classification.\n",
    "    \"\"\"\n",
    "    def __init__(self, vocab_size, embedding_dim, hidden_size, num_labels, dropout_p=0.1):\n",
    "        super(BiLSTM_Classifier, self).__init__()\n",
    "        \n",
    "        # --- Parameters ---\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_classes = num_labels\n",
    "        self.num_directions = 2 # Fixed for BiLSTM\n",
    "\n",
    "        # --- Embedding Layer ---\n",
    "        # input: (batch_size, seq_len) -> indices of tokens\n",
    "        # output: (batch_size, seq_len, embedding_dim) -> dense word vectors\n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
    "        \n",
    "        # --- Dropout Layer ---\n",
    "        # Applied after embedding to regularize word vectors (Embedding Dropout)\n",
    "        self.dropout = nn.Dropout(dropout_p)\n",
    "        \n",
    "        # --- BiLSTM Layer ---\n",
    "        # input_size: embedding_dim (the size of the input features per time step)\n",
    "        # hidden_size: hidden_size (the output size of the hidden state for ONE direction)\n",
    "        # batch_first=True: input shape is (batch_size, seq_len, features)\n",
    "        # bidirectional=True: output_dim = 2 * hidden_size\n",
    "        self.lstm = nn.LSTM(embedding_dim, hidden_size, batch_first=True, bidirectional=True)\n",
    "        \n",
    "        # --- Classification Layer (MLP) ---\n",
    "        # The BiLSTM combines the final forward and backward hidden states.\n",
    "        # Input size to the Linear layer must be (2 * hidden_size)\n",
    "        # Output size is num_labels (e.g., 2 for positive/negative)\n",
    "        self.classifier = nn.Linear(self.num_directions * hidden_size, num_labels)\n",
    "\n",
    "    def forward(self, input_tensor):\n",
    "        # 1. Embedding\n",
    "        # shape: (bs, seq_len) -> (bs, seq_len, embedding_dim)\n",
    "        embedded = self.dropout(self.embedding(input_tensor))\n",
    "    \n",
    "        # 2. BiLSTM Processing\n",
    "        # output: (bs, seq_len, 2 * hidden_size) - full sequence output\n",
    "        # (hidden, cell): state from both directions, shape: (2, bs, hidden_size)\n",
    "        lstm_out, (hidden, cell) = self.lstm(embedded)\n",
    "        print(f\"lstm_out shape: {lstm_out.shape}\")    # (batch_size, seq_len, 2*hidden_size)\n",
    "        print(f\"hidden shape: {hidden.shape}\")        # (2, batch_size, hidden_size)\n",
    "        print(f\"cell shape: {cell.shape}\")            # (2, batch_size, hidden_size)\n",
    "        \n",
    "        # 3. Aggregate Hidden States for Classification\n",
    "        # We take the final hidden state: \n",
    "        # hidden[0] is the final forward state\n",
    "        # hidden[1] is the final backward state\n",
    "        # We flatten and concatenate them to get the aggregated sentence context.\n",
    "        # shape: (2, bs, hidden_size) -> (bs, 2 * hidden_size)\n",
    "        \n",
    "        # We detach the hidden states from the full sequence output, as is common for classification\n",
    "        hidden = hidden.view(self.num_directions, -1, self.hidden_size) # Reshape if necessary (optional in this setup, but safer)\n",
    "        final_hidden = torch.cat((hidden[-2, :, :], hidden[-1, :, :]), dim=1)\n",
    "        \n",
    "        # 4. Final Classification\n",
    "        # input: (bs, 2 * hidden_size)\n",
    "        # output: (bs, num_classes)\n",
    "        prediction_logits = self.classifier(final_hidden)\n",
    "        \n",
    "        # For sentiment classification, we only need the final prediction\n",
    "        return prediction_logits\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9b4420ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 5, 15, 25, 11, 14, 24, 20, 35,  7, 24],\n",
      "        [ 9, 31,  2, 11, 17, 37, 14, 24, 12, 18],\n",
      "        [23,  2, 21,  8, 36, 30,  8, 25, 34, 33],\n",
      "        [ 0, 18,  7, 30, 39, 22, 16, 39, 26, 25]])\n",
      "Embedding shape:  torch.Size([4, 10, 256])\n",
      "torch.Size([4, 10, 512])\n"
     ]
    }
   ],
   "source": [
    "hidden_size = 256 \n",
    "bs = 4\n",
    "seq_len = 10\n",
    "vocab_size = 40\n",
    "embedding_dim = 256\n",
    "num_labels = 2\n",
    "\n",
    "lstm = BiLSTM_Classifier(\n",
    "    vocab_size = vocab_size,\n",
    "    embedding_dim = embedding_dim,\n",
    "    hidden_size = hidden_size,\n",
    "    num_labels = num_labels\n",
    ")\n",
    ")\n",
    "\n",
    "# Create a batch of random indices (simulating tokenized word ids)\n",
    "# Embedding expects input of dtype torch.long (not float)\n",
    "t = torch.randint(low=0, high=vocab_size, size=(bs, seq_len), dtype=torch.long)\n",
    "print(t)\n",
    "out = lstm(t)\n",
    "print(f\"Final output shape: {out.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a550ce2e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}