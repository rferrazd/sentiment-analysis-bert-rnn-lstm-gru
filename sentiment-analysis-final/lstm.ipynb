{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ba0fc5ed",
   "metadata": {},
   "source": [
    "# LSTM \n",
    "\n",
    "Implementation based on code from notebook: 1. Encoder-Decoder Seq2Seq.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dc8885c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np \n",
    "import torch \n",
    "from gensim.models import Word2Vec\n",
    "from torch.nn import functional as F\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "\n",
    "SEED = 42\n",
    "np.random.seed(SEED)\n",
    "\n",
    "# Load the datasets \n",
    "with open(\"train.pkl\", \"rb\") as f:\n",
    "    train = pickle.load(f)\n",
    "with open(\"val.pkl\", \"rb\") as f:\n",
    "    val = pickle.load(f)\n",
    "with open(\"test.pkl\", \"rb\") as f:\n",
    "    test = pickle.load(f)\n",
    "\n",
    "num_labels = train['label'].nunique()\n",
    "print(\"Number of labels: \", num_labels)\n",
    "labels = [label for i, label in enumerate(train['label'].value_counts().index)]\n",
    "labels\n",
    "label_0 = labels[1]\n",
    "label_4 = labels[0]\n",
    "print(f\"Label 0: {label_0} and label 4: {label_4}\")\n",
    "\n",
    "train.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c6944bc",
   "metadata": {},
   "source": [
    "# LSTM Encoder "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7d86429",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch\n",
    "class BiLSTM_Classifier(nn.Module):\n",
    "    \"\"\"\n",
    "    A Bidirectional LSTM-based module designed for sequence encoding\n",
    "    and subsequent sentiment classification.\n",
    "    \"\"\"\n",
    "    def __init__(self, vocab_size, embedding_dim, hidden_size, num_labels, dropout_p=0.1):\n",
    "        super(BiLSTM_Classifier, self).__init__()\n",
    "        \n",
    "        # --- Parameters ---\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_classes = num_labels\n",
    "        self.num_directions = 2 # Fixed for BiLSTM\n",
    "\n",
    "        # --- Embedding Layer ---\n",
    "        # input: (batch_size, seq_len) -> indices of tokens\n",
    "        # output: (batch_size, seq_len, embedding_dim) -> dense word vectors\n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
    "        \n",
    "        # --- Dropout Layer ---\n",
    "        # Applied after embedding to regularize word vectors (Embedding Dropout)\n",
    "        self.dropout = nn.Dropout(dropout_p)\n",
    "        \n",
    "        # --- BiLSTM Layer ---\n",
    "        # input_size: embedding_dim (the size of the input features per time step)\n",
    "        # hidden_size: hidden_size (the output size of the hidden state for ONE direction)\n",
    "        # batch_first=True: input shape is (batch_size, seq_len, features)\n",
    "        # bidirectional=True: output_dim = 2 * hidden_size\n",
    "        self.lstm = nn.LSTM(embedding_dim, hidden_size, batch_first=True, bidirectional=True)\n",
    "        \n",
    "        # --- Classification Layer (MLP) ---\n",
    "        # The BiLSTM combines the final forward and backward hidden states.\n",
    "        # Input size to the Linear layer must be (2 * hidden_size)\n",
    "        # Output size is num_labels (e.g., 2 for positive/negative)\n",
    "        self.classifier = nn.Linear(self.num_directions * hidden_size, num_labels)\n",
    "\n",
    "    def forward(self, input_tensor):\n",
    "        # 1. Embedding\n",
    "        # shape: (bs, seq_len) -> (bs, seq_len, embedding_dim)\n",
    "        embedded = self.dropout(self.embedding(input_tensor))\n",
    "    \n",
    "        # 2. BiLSTM Processing\n",
    "        # output: (bs, seq_len, 2 * hidden_size) - full sequence output\n",
    "        # (hidden, cell): state from both directions, shape: (2, bs, hidden_size)\n",
    "        lstm_out, (hidden, cell) = self.lstm(embedded)\n",
    "        print(f\"lstm_out shape: {lstm_out.shape}\")    # (batch_size, seq_len, 2*hidden_size)\n",
    "        print(f\"hidden shape: {hidden.shape}\")        # (2, batch_size, hidden_size)\n",
    "        print(f\"cell shape: {cell.shape}\")            # (2, batch_size, hidden_size)\n",
    "        \n",
    "        # 3. Aggregate Hidden States for Classification\n",
    "\n",
    "        print(f\"Before view, hidden shape: {hidden.shape}\")  # Should be (num_directions, batch_size, hidden_size)\n",
    "        hidden = hidden.view(self.num_directions, -1, self.hidden_size) # Reshape if necessary (optional in this setup, but safer)\n",
    "        print(f\"After view, hidden shape: {hidden.shape}\")   # Should be (num_directions, batch_size, hidden_size)\n",
    "        \n",
    "        # Print hidden[-2] and hidden[-1] shapes before concatenation\n",
    "        print(f\"hidden[-2] (forward) shape: {hidden[-2, :, :].shape}\")  # (batch_size, hidden_size)\n",
    "        print(f\"hidden[-1] (backward) shape: {hidden[-1, :, :].shape}\") # (batch_size, hidden_size)\n",
    "        \n",
    "        final_hidden = torch.cat((hidden[-2, :, :], hidden[-1, :, :]), dim=1)\n",
    "        print(f\"Concatenated final_hidden shape: {final_hidden.shape}\") # (batch_size, 2 * hidden_size)\n",
    "        \n",
    "        # 4. Final Classification\n",
    "        # input: (bs, 2 * hidden_size)\n",
    "        # output: (bs, num_classes)\n",
    "        prediction_logits = self.classifier(final_hidden)\n",
    "        print(f\"prediction_logits shape: {prediction_logits.shape}\") # (batch_size, num_classes)\n",
    "        # For sentiment classification, we only need the final prediction\n",
    "        return prediction_logits\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b4420ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "bs = 4\n",
    "seq_len = 5\n",
    "vocab_size = 20\n",
    "lstm = BiLSTM_Classifier(\n",
    "    vocab_size = vocab_size, \n",
    "    embedding_dim=10,\n",
    "    hidden_size=15, \n",
    "    num_labels=2\n",
    ")\n",
    "\n",
    "# Create a batch of random indices (simulating tokenized word ids)\n",
    "# Embedding expects input of dtype torch.long (not float)\n",
    "t = torch.randint(low=0, high=vocab_size, size=(bs, seq_len), dtype=torch.long)\n",
    "prediction_logits= lstm(t)\n",
    "print(prediction_logits.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01cd3361",
   "metadata": {},
   "source": [
    "# Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a550ce2e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a20db822",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad8eb59a",
   "metadata": {},
   "source": [
    "## Train and Validation Sets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b5a9629",
   "metadata": {},
   "source": [
    "##  Test Sets"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
