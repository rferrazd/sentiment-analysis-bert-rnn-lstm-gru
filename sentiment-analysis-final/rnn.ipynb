{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "82de422e",
   "metadata": {},
   "source": [
    "# RNN\n",
    "\n",
    "*INSTRUCTIONS*\n",
    "Embedding for RNN-based Models:\n",
    "    ○ Generate wordembeddings using GloVeorWord2Vec.\n",
    "    ○ Pad sequences to a fixed length for uniformity\n",
    "\n",
    "Steps were taken from notebook: Module 3 - Video 6 onwards.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f5ace5e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: mps\n",
      "Number of labels:  2\n",
      "Label 0: 0 and label 4: 4\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>polarity of tweet</th>\n",
       "      <th>id of the tweet</th>\n",
       "      <th>date of the tweet</th>\n",
       "      <th>query</th>\n",
       "      <th>user</th>\n",
       "      <th>text of the tweet</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>237034</th>\n",
       "      <td>0</td>\n",
       "      <td>2058468667</td>\n",
       "      <td>Sat Jun 06 15:00:18 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>bestthingaround</td>\n",
       "      <td>my star trek bootleg timed out and when i refr...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1387008</th>\n",
       "      <td>0</td>\n",
       "      <td>2068651245</td>\n",
       "      <td>Sun Jun 07 14:27:20 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>Scriblit</td>\n",
       "      <td>yeah but the really pretty ones only go up to ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         polarity of tweet  id of the tweet             date of the tweet  \\\n",
       "237034                   0       2058468667  Sat Jun 06 15:00:18 PDT 2009   \n",
       "1387008                  0       2068651245  Sun Jun 07 14:27:20 PDT 2009   \n",
       "\n",
       "            query             user  \\\n",
       "237034   NO_QUERY  bestthingaround   \n",
       "1387008  NO_QUERY         Scriblit   \n",
       "\n",
       "                                         text of the tweet  label  \n",
       "237034   my star trek bootleg timed out and when i refr...      0  \n",
       "1387008  yeah but the really pretty ones only go up to ...      0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pickle\n",
    "import re\n",
    "import numpy as np \n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "import torch \n",
    "from gensim.models import Word2Vec\n",
    "from torch.nn import functional as F\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "\n",
    "SEED = 42\n",
    "np.random.seed(SEED)\n",
    "\n",
    "# Check the available device\n",
    "if torch.cuda.is_available():\n",
    "    device = \"cuda\"\n",
    "    torch.cuda.manual_seed_all(SEED)\n",
    "elif torch.backends.mps.is_available():\n",
    "    device = \"mps\"\n",
    "else:\n",
    "    device = \"cpu\"\n",
    "\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# Load the datasets \n",
    "with open(\"train.pkl\", \"rb\") as f:\n",
    "    train = pickle.load(f)\n",
    "with open(\"val.pkl\", \"rb\") as f:\n",
    "    val = pickle.load(f)\n",
    "with open(\"test.pkl\", \"rb\") as f:\n",
    "    test = pickle.load(f)\n",
    "\n",
    "num_labels = train['label'].nunique()\n",
    "print(\"Number of labels: \", num_labels)\n",
    "labels = [label for i, label in enumerate(train['label'].value_counts().index)]\n",
    "labels\n",
    "label_0 = labels[1]\n",
    "label_4 = labels[0]\n",
    "print(f\"Label 0: {label_0} and label 4: {label_4}\")\n",
    "\n",
    "train.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edec17c5",
   "metadata": {},
   "source": [
    "# Utils "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d122a645",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:12: SyntaxWarning: invalid escape sequence '\\s'\n",
      "<>:12: SyntaxWarning: invalid escape sequence '\\s'\n",
      "/var/folders/9v/0z2cy6c546g6bvh2dzly39x80000gn/T/ipykernel_9815/3294288950.py:12: SyntaxWarning: invalid escape sequence '\\s'\n",
      "  pattern = f\"[a-zA-Z\\s]\"\n"
     ]
    }
   ],
   "source": [
    "# ---------------------------------------\n",
    "# Utils\n",
    "# ---------------------------------------\n",
    "\n",
    "# Function to convert text to tokens \n",
    "def preprocess_text(text):\n",
    "    # Check if the text is a string\n",
    "    if not isinstance(text, str):\n",
    "        return []\n",
    "    \n",
    "    # Keep only letters and whitespaces\n",
    "    pattern = f\"[a-zA-Z\\s]\"\n",
    "    text = ''.join(re.findall(pattern, text))\n",
    "    \n",
    "    # Convert to lowercase\n",
    "    text = text.lower()\n",
    "    \n",
    "    # Tokenize the text\n",
    "    tokens = nltk.word_tokenize(text)\n",
    "    \n",
    "    return tokens\n",
    "# Function to convert tokens to Word2Vec embeddings\n",
    "def text_to_embeddings(text, word2vec_model, seq_length):\n",
    "    \"\"\"\n",
    "    Function to convert a given text into a sequence of embeddings using a pretrained Word2Vec model\n",
    "    \n",
    "    \"\"\"\n",
    "    embeddings = []\n",
    "    \n",
    "    for i, word in enumerate(text):\n",
    "        if word in word2vec_model.wv:\n",
    "            if i == seq_length:\n",
    "                break\n",
    "            embeddings.append(word2vec_model.wv[word])\n",
    "        else: # skip word if to in word2vec_model's vocabulary\n",
    "            continue\n",
    "        \n",
    "    # Padding the sequences\n",
    "    if len(embeddings) < seq_length:\n",
    "        zero_padding = [np.zeros(word2vec_model.vector_size) \\\n",
    "                        for _ in range(seq_length - len(embeddings))]\n",
    "\n",
    "        embeddings = embeddings + zero_padding\n",
    "\n",
    "    # sequence of word vectors of length seq_length\n",
    "    return embeddings[:seq_length]\n",
    "# Text -> Embeddings -> torch tokens\n",
    "def prepare_data(reviews, labels, word2vec_model, seq_length):\n",
    "    X = [text_to_embeddings(review, word2vec_model, seq_length) for review in reviews]\n",
    "    X_array = np.array(X)\n",
    "    X_tensor = torch.tensor(X_array)\n",
    "    y = torch.tensor(labels, dtype=torch.long)\n",
    "    return X_tensor, y\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1072b94",
   "metadata": {},
   "source": [
    "# Word2Vec Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a172ded3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
      "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
      "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
      "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
      "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
      "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
      "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
      "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
      "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
      "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
      "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
      "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
      "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocab size:  27\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# 1) Tokenize the tweet reviwes\n",
    "train['tokens'] = train['text of the tweet'].apply(preprocess_text)\n",
    "val['tokens'] = val['text of the tweet'].apply(preprocess_text)\n",
    "test['tokens'] = test['text of the tweet'].apply(preprocess_text)\n",
    "\n",
    "seq_length = 100\n",
    "# 2) Create vocabulary using word2vec\n",
    "word2vec_model = Word2Vec(sentences=train['text of the tweet'].values.tolist(), \n",
    "                          vector_size=seq_length, # same as in Module 3 - Video 6 onwards.ipynb\n",
    "                           min_count=1, \n",
    "                           workers=4)\n",
    "\n",
    "# Get vocabulary size\n",
    "vocab_size = len(word2vec_model.wv)\n",
    "print(\"Vocab size: \", vocab_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37c352b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define hyperparameters\n",
    "input_size = word2vec_model.vector_size\n",
    "hidden_size = 128\n",
    "output_size = 1\n",
    "num_layers = 1\n",
    "learning_rate = 0.001\n",
    "num_epochs = 30\n",
    "batch_size = 64\n",
    "dropout_rate = 0.5\n",
    "leaky_relu_slope = 0.1\n",
    "\n",
    "# Prepare data\n",
    "X_train, y_train = prepare_data(train['tokens'], train['label'],\n",
    "                    word2vec_model, seq_length=seq_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a957d9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_val, y_val = prepare_data(val['tokens'], val['label'],\n",
    "                    word2vec_model, seq_length=seq_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c987308c",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test, y_test = prepare_data(test['tokens'], test['label'],\n",
    "                    word2vec_model, seq_length=seq_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9192ac0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create DataLoader\n",
    "train_data = TensorDataset(X_train, y_train)\n",
    "train_loader = DataLoader(train_data, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "# Create DataLoader\n",
    "val_data = TensorDataset(X_val, y_val)\n",
    "val_loader = DataLoader(val_data, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "\n",
    "test_data = TensorDataset(X_test, y_test)\n",
    "test_loader = DataLoader(test_data, batch_size=batch_size, shuffle=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48cdd93f",
   "metadata": {},
   "source": [
    "# Define the RNN model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b9622ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SentimentRNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size, num_layers, dropout_rate):\n",
    "        super(SentimentRNN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        # Basic RNN layer\n",
    "        # shape of input tensor: (batch_size, seq_length, input_size)\n",
    "        self.rnn = nn.RNN(input_size, hidden_size, num_layers, batch_first=True, dropout=dropout_rate if num_layers > 1 else 0)\n",
    "        self.leaky_relu = nn.LeakyReLU()  # Leaky ReLU activation layer\n",
    "        self.dropout = nn.Dropout(dropout_rate)\n",
    "        self.fc = nn.Linear(hidden_size, output_size)\n",
    "        self.sigmoid = nn.Sigmoid()  # Sigmoid activation layer\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Initial hidden state\n",
    "        # h0 shape: (num_layers, batch_size, hidden_size)\n",
    "        h0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(x.device)\n",
    "        # RNN output\n",
    "        # out shape after rnn: (batch_size, seq_length, hidden_size)\n",
    "        out, _ = self.rnn(x, h0)\n",
    "        # Apply Leaky ReLU to the outputs of the RNN layer\n",
    "        # out shape: (batch_size, seq_length, hidden_size)\n",
    "        out = self.leaky_relu(out)\n",
    "        out = self.dropout(out)\n",
    "        # Get the last sequence output for classification\n",
    "        # out shape after indexing: (batch_size, hidden_size)\n",
    "        out = out[:, -1, :]\n",
    "        # Apply the linear layer for the final output\n",
    "        # out shape after fc: (batch_size, output_size)\n",
    "        out = self.fc(out)\n",
    "        # Apply the sigmoid activation\n",
    "        # out shape after sigmoid: (batch_size, output_size)\n",
    "        out = self.sigmoid(out)\n",
    "        # shape of output tensor: (batch_size, output_size)\n",
    "        return out\n",
    "\n",
    "# Initialize model, loss function, and optimizer\n",
    "model = SentimentRNN(input_size, hidden_size, output_size, num_layers, dropout_rate).to(device)\n",
    "criterion = nn.BCELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "# Print the number of trainable parameters\n",
    "num_trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "print(f'Number of trainable parameters: {num_trainable_params}')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d43b8575",
   "metadata": {},
   "source": [
    "# Evaluation Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "215c7103",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "def evaluate_model(loader, label_0, label_4, plot_confusion_matrix=True, title=\"Confusion Matrix\"):\n",
    "    \"\"\"\n",
    "    Efficient single-pass evaluation function that computes all metrics at once.\n",
    "    \n",
    "    Args:\n",
    "        loader: DataLoader containing batches of (inputs, labels)\n",
    "        label_0: Integer label for negative sentiment (e.g., 0)\n",
    "        label_4: Integer label for positive sentiment (e.g., 4)\n",
    "        plot_confusion_matrix: Whether to plot the confusion matrix (default: False)\n",
    "        title: Title for confusion matrix plot (default: \"Confusion Matrix\")\n",
    "    \n",
    "    Returns:\n",
    "        Dictionary containing:\n",
    "        - accuracy: Overall accuracy percentage\n",
    "        - precision_label_0, recall_label_0, f1_label_0: Metrics for label_0\n",
    "        - precision_label_4, recall_label_4, f1_label_4: Metrics for label_4\n",
    "        - confusion_matrix: 2x2 numpy array [TN, FP; FN, TP]\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    \n",
    "    # Initialize counts for metrics\n",
    "    tp_0, fp_0, fn_0 = 0, 0, 0  # For label_0 (negative)\n",
    "    tp_4, fp_4, fn_4 = 0, 0, 0  # For label_4 (positive)\n",
    "    \n",
    "    # Collect all predictions and labels for confusion matrix\n",
    "    all_predictions = []\n",
    "    all_labels = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in loader:\n",
    "            # inputs shape: (batch_size, seq_length, input_size)\n",
    "            # labels shape: (batch_size,)\n",
    "            \n",
    "            outputs = model(inputs)\n",
    "            # outputs shape after model: (batch_size, 1) - sigmoid probabilities\n",
    "            \n",
    "            outputs = outputs.squeeze()\n",
    "            # outputs shape after squeeze: (batch_size,) - 1D tensor of probabilities [0, 1]\n",
    "            \n",
    "            # Convert probabilities to binary predictions (0 or 1)\n",
    "            # binary_predictions shape: (batch_size,) - binary values [0, 1]\n",
    "            binary_predictions = (outputs > 0.5).long()\n",
    "            \n",
    "            # Map binary predictions to actual labels: 0 -> label_0, 1 -> label_4\n",
    "            # predictions shape: (batch_size,) - contains label_0 or label_4\n",
    "            predictions = torch.where(binary_predictions == 0, label_0, label_4)\n",
    "            \n",
    "            # Store for confusion matrix\n",
    "            all_predictions.extend(predictions.cpu().numpy())\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "            # Calculate True Positives, False Positives, False Negatives for label_0\n",
    "            # TP: predicted label_0 AND actual label_0\n",
    "            tp_0 += ((predictions == label_0) & (labels == label_0)).sum().item()\n",
    "            # FP: predicted label_0 BUT actual is NOT label_0 (i.e., label_4)\n",
    "            fp_0 += ((predictions == label_0) & (labels != label_0)).sum().item()\n",
    "            # FN: predicted NOT label_0 (i.e., label_4) BUT actual is label_0\n",
    "            fn_0 += ((predictions != label_0) & (labels == label_0)).sum().item()\n",
    "            \n",
    "            # Calculate True Positives, False Positives, False Negatives for label_4\n",
    "            # TP: predicted label_4 AND actual label_4\n",
    "            tp_4 += ((predictions == label_4) & (labels == label_4)).sum().item()\n",
    "            # FP: predicted label_4 BUT actual is NOT label_4 (i.e., label_0)\n",
    "            fp_4 += ((predictions == label_4) & (labels != label_4)).sum().item()\n",
    "            # FN: predicted NOT label_4 (i.e., label_0) BUT actual is label_4\n",
    "            fn_4 += ((predictions != label_4) & (labels == label_4)).sum().item()\n",
    "\n",
    "    # Calculate accuracy\n",
    "    total = len(all_labels)\n",
    "    correct = sum(1 for p, l in zip(all_predictions, all_labels) if p == l)\n",
    "    accuracy = 100 * correct / total if total > 0 else 0.0\n",
    "\n",
    "    # Calculate precision = TP / (TP + FP) - how many predicted positives were actually positive\n",
    "    precision_0 = tp_0 / (tp_0 + fp_0) if (tp_0 + fp_0) > 0 else 0.0\n",
    "    precision_4 = tp_4 / (tp_4 + fp_4) if (tp_4 + fp_4) > 0 else 0.0\n",
    "    \n",
    "    # Calculate recall = TP / (TP + FN) - how many actual positives were correctly predicted\n",
    "    recall_0 = tp_0 / (tp_0 + fn_0) if (tp_0 + fn_0) > 0 else 0.0\n",
    "    recall_4 = tp_4 / (tp_4 + fn_4) if (tp_4 + fn_4) > 0 else 0.0\n",
    "    \n",
    "    # Calculate F1-score = 2 * (precision * recall) / (precision + recall) - harmonic mean\n",
    "    f1_0 = 2*(precision_0*recall_0) / (precision_0+recall_0) if (precision_0+recall_0) > 0 else 0.0\n",
    "    f1_4 = 2*(precision_4*recall_4) / (precision_4+recall_4) if (precision_4+recall_4) > 0 else 0.0\n",
    "\n",
    "    # Create confusion matrix\n",
    "    cm = confusion_matrix(all_labels, all_predictions, labels=[label_0, label_4])\n",
    "    \n",
    "    # Plot confusion matrix if requested\n",
    "    if plot_confusion_matrix:\n",
    "        plt.figure(figsize=(8, 6))\n",
    "        sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', \n",
    "                    xticklabels=[f'Negative ({label_0})', f'Positive ({label_4})'],\n",
    "                    yticklabels=[f'Negative ({label_0})', f'Positive ({label_4})'],\n",
    "                    cbar_kws={'label': 'Count'})\n",
    "        plt.title(title, fontsize=14, fontweight='bold', pad=20)\n",
    "        plt.ylabel('True Label', fontsize=12, fontweight='bold')\n",
    "        plt.xlabel('Predicted Label', fontsize=12, fontweight='bold')\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "        \n",
    "        # Print summary\n",
    "        tn, fp, fn, tp = cm.ravel()\n",
    "        print(f\"\\nConfusion Matrix Summary:\")\n",
    "        print(f\"True Negatives (TN):  {tn:6d}  - Correctly predicted {label_0}\")\n",
    "        print(f\"False Positives (FP): {fp:6d}  - Predicted {label_4} but actual was {label_0}\")\n",
    "        print(f\"False Negatives (FN):  {fn:6d}  - Predicted {label_0} but actual was {label_4}\")\n",
    "        print(f\"True Positives (TP):  {tp:6d}  - Correctly predicted {label_4}\")\n",
    "        print(f\"Total samples: {tn + fp + fn + tp}\")\n",
    "\n",
    "    return {\n",
    "        'accuracy': accuracy,\n",
    "        'precision_label_0': precision_0, \n",
    "        'recall_label_0': recall_0,\n",
    "        'f1_label_0': f1_0,\n",
    "        'precision_label_4': precision_4, \n",
    "        'recall_label_4': recall_4,\n",
    "        'f1_label_4': f1_4,\n",
    "        'confusion_matrix': cm\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bb65eef",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9ce77d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Training loop\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "num_epochs = 30  # Number of epochs\n",
    "losses = []  # List to store the average train loss per epoch\n",
    "val_losses = []  # List to store the average validation loss per epoch\n",
    "best_val_loss = float('inf')  # Initialize the best validation loss to infinity\n",
    "best_epoch = 0  # Epoch with the best validation loss\n",
    "patience = 0\n",
    "max_patience = 3  # Maximum epochs to wait for improvement\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()  # Set the model to training mode\n",
    "    total_loss = 0\n",
    "    total_val_loss = 0\n",
    "    count = 0\n",
    "    val_count = 0\n",
    "    for inputs, labels in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        outputs = outputs.squeeze()\n",
    "        loss = criterion(outputs, labels.float())\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "        count += 1\n",
    "    average_loss = total_loss / count\n",
    "    losses.append(average_loss)\n",
    "\n",
    "    model.eval()  # Set the model to evaluation mode\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in val_loader:\n",
    "            val_outputs = model(inputs)\n",
    "            val_outputs = val_outputs.squeeze()\n",
    "            val_loss = criterion(val_outputs, labels.float())\n",
    "            total_val_loss += val_loss.item()\n",
    "            val_count += 1\n",
    "    average_val_loss = total_val_loss / val_count\n",
    "    val_losses.append(average_val_loss)\n",
    "    print(f'Epoch {epoch+1}/{num_epochs}, Loss: {average_loss:.4f}, Val Loss: {average_val_loss:.4f}')\n",
    "    \n",
    "    # Check if the current validation loss is the lowest; if so, save the model\n",
    "    if average_val_loss < best_val_loss:\n",
    "        best_val_loss = average_val_loss\n",
    "        best_epoch = epoch\n",
    "        torch.save(model.state_dict(), 'rnn_best_model.pth')  # Save the best model\n",
    "        patience = 0   \n",
    "    else:\n",
    "        patience += 1\n",
    "\n",
    "    if patience >= max_patience:\n",
    "        print(f'Early stopped at {epoch+1}')\n",
    "        break  # Stop training\n",
    "\n",
    "print(f'Lowest Validation Loss: {best_val_loss:.4f} at Epoch {best_epoch + 1}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "407117aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the best model and calculate accuracy only for that\n",
    "model.load_state_dict(torch.load('rnn_best_model.pth'))\n",
    "# After training, evaluate on validation set (with confusion matrix plot)\n",
    "val_metrics = evaluate_model(val_loader, label_0, label_4, \n",
    "                              plot_confusion_matrix=True, \n",
    "                              title=\"Validation Set Confusion Matrix\")\n",
    "\n",
    "print(f\"Validation Accuracy: {val_metrics['accuracy']:.2f}%\")\n",
    "print(f\"Validation Metrics: {val_metrics}\")\n",
    "\n",
    "# Evaluate on test set (without plot)\n",
    "test_metrics = evaluate_model(test_loader, label_0, label_4, \n",
    "                              plot_confusion_matrix=False)\n",
    "print(f\"Test Accuracy: {test_metrics['accuracy']:.2f}%\")\n",
    "\n",
    "# Or plot test confusion matrix separately\n",
    "test_metrics = evaluate_model(test_loader, label_0, label_4, \n",
    "                              plot_confusion_matrix=True,\n",
    "                              title=\"Test Set Confusion Matrix\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
