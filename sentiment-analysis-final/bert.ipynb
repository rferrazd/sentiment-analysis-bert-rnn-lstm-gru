{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "91223976",
   "metadata": {},
   "source": [
    "# BERT\n",
    "Tokenizer: WordPiece\n",
    "\n",
    "EvaluationMetrics\n",
    "    ● Accuracy:Overall percentage of correct predictions.\n",
    "    ● Precision,Recall,F1-Score:Evaluate per class(negative,neutral, positive).\n",
    "    ● Confusion Matrix:Show performance across all classes.\n",
    "    ● ROC-AUCScore: Measure the ability of the model to distinguish between classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "0779ea38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: mps\n",
      "Number of labels (label):  2\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>polarity of tweet</th>\n",
       "      <th>id of the tweet</th>\n",
       "      <th>date of the tweet</th>\n",
       "      <th>query</th>\n",
       "      <th>user</th>\n",
       "      <th>text of the tweet</th>\n",
       "      <th>label</th>\n",
       "      <th>label_original</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>237034</th>\n",
       "      <td>0</td>\n",
       "      <td>2058468667</td>\n",
       "      <td>Sat Jun 06 15:00:18 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>bestthingaround</td>\n",
       "      <td>my star trek bootleg timed out and when i refr...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1387008</th>\n",
       "      <td>0</td>\n",
       "      <td>2068651245</td>\n",
       "      <td>Sun Jun 07 14:27:20 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>Scriblit</td>\n",
       "      <td>yeah but the really pretty ones only go up to ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>188849</th>\n",
       "      <td>4</td>\n",
       "      <td>1880531009</td>\n",
       "      <td>Fri May 22 01:34:29 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>mayank</td>\n",
       "      <td>cheers to for helping me with awesome jaljeera...</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1499236</th>\n",
       "      <td>0</td>\n",
       "      <td>1964084200</td>\n",
       "      <td>Fri May 29 13:42:01 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>kendramcd13</td>\n",
       "      <td>shes not coming to detroit only grand rapids i...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1275209</th>\n",
       "      <td>4</td>\n",
       "      <td>1693147717</td>\n",
       "      <td>Sun May 03 21:41:44 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>upleftdown</td>\n",
       "      <td>quotthis next songs about my herpes its called...</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1458531</th>\n",
       "      <td>0</td>\n",
       "      <td>2210194650</td>\n",
       "      <td>Wed Jun 17 11:17:03 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>pleasebemine</td>\n",
       "      <td>i couldnt see you did you go just with your mum</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1280305</th>\n",
       "      <td>0</td>\n",
       "      <td>2265141928</td>\n",
       "      <td>Sun Jun 21 05:53:35 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>foreverorbiting</td>\n",
       "      <td>yeah keep pimpin have to go to spain thought i...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>332794</th>\n",
       "      <td>0</td>\n",
       "      <td>1882951522</td>\n",
       "      <td>Fri May 22 07:45:47 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>barnymilla</td>\n",
       "      <td>truly addicted d well leave around pm tonight ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>483748</th>\n",
       "      <td>0</td>\n",
       "      <td>2242058240</td>\n",
       "      <td>Fri Jun 19 11:42:58 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>PRETTi_PUNK</td>\n",
       "      <td>going to eat then more unpacking im almost don...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1340980</th>\n",
       "      <td>0</td>\n",
       "      <td>2062574195</td>\n",
       "      <td>Sat Jun 06 23:38:02 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>medras_13</td>\n",
       "      <td>studying japanese on hours of sleep has given ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         polarity of tweet  id of the tweet             date of the tweet  \\\n",
       "237034                   0       2058468667  Sat Jun 06 15:00:18 PDT 2009   \n",
       "1387008                  0       2068651245  Sun Jun 07 14:27:20 PDT 2009   \n",
       "188849                   4       1880531009  Fri May 22 01:34:29 PDT 2009   \n",
       "1499236                  0       1964084200  Fri May 29 13:42:01 PDT 2009   \n",
       "1275209                  4       1693147717  Sun May 03 21:41:44 PDT 2009   \n",
       "1458531                  0       2210194650  Wed Jun 17 11:17:03 PDT 2009   \n",
       "1280305                  0       2265141928  Sun Jun 21 05:53:35 PDT 2009   \n",
       "332794                   0       1882951522  Fri May 22 07:45:47 PDT 2009   \n",
       "483748                   0       2242058240  Fri Jun 19 11:42:58 PDT 2009   \n",
       "1340980                  0       2062574195  Sat Jun 06 23:38:02 PDT 2009   \n",
       "\n",
       "            query             user  \\\n",
       "237034   NO_QUERY  bestthingaround   \n",
       "1387008  NO_QUERY         Scriblit   \n",
       "188849   NO_QUERY           mayank   \n",
       "1499236  NO_QUERY      kendramcd13   \n",
       "1275209  NO_QUERY       upleftdown   \n",
       "1458531  NO_QUERY     pleasebemine   \n",
       "1280305  NO_QUERY  foreverorbiting   \n",
       "332794   NO_QUERY       barnymilla   \n",
       "483748   NO_QUERY      PRETTi_PUNK   \n",
       "1340980  NO_QUERY        medras_13   \n",
       "\n",
       "                                         text of the tweet  label  \\\n",
       "237034   my star trek bootleg timed out and when i refr...      0   \n",
       "1387008  yeah but the really pretty ones only go up to ...      0   \n",
       "188849   cheers to for helping me with awesome jaljeera...      1   \n",
       "1499236  shes not coming to detroit only grand rapids i...      0   \n",
       "1275209  quotthis next songs about my herpes its called...      1   \n",
       "1458531    i couldnt see you did you go just with your mum      0   \n",
       "1280305  yeah keep pimpin have to go to spain thought i...      0   \n",
       "332794   truly addicted d well leave around pm tonight ...      0   \n",
       "483748   going to eat then more unpacking im almost don...      0   \n",
       "1340980  studying japanese on hours of sleep has given ...      0   \n",
       "\n",
       "         label_original  \n",
       "237034                0  \n",
       "1387008               0  \n",
       "188849                4  \n",
       "1499236               0  \n",
       "1275209               4  \n",
       "1458531               0  \n",
       "1280305               0  \n",
       "332794                0  \n",
       "483748                0  \n",
       "1340980               0  "
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pickle\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from tqdm import tqdm\n",
    "\n",
    "# local imports\n",
    "from bert_metrics import (\n",
    "    calculate_precision_recall_f1,\n",
    "    calculate_accuracy,\n",
    "    get_confusion_matrix,\n",
    "    plot_confusion_matrix,\n",
    ")\n",
    "\n",
    "SEED = 42\n",
    "np.random.seed(SEED)\n",
    "\n",
    "# Check the available device\n",
    "if torch.cuda.is_available():\n",
    "    device = \"cuda\"\n",
    "    torch.cuda.manual_seed_all(SEED)\n",
    "elif torch.backends.mps.is_available():\n",
    "    device = \"mps\"\n",
    "else:\n",
    "    device = \"cpu\"\n",
    "\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# Load the datasets\n",
    "with open(\"data/train.pkl\", \"rb\") as f:\n",
    "    train = pickle.load(f)\n",
    "with open(\"data/val.pkl\", \"rb\") as f:\n",
    "    val = pickle.load(f)\n",
    "with open(\"data/test.pkl\", \"rb\") as f:\n",
    "    test = pickle.load(f)\n",
    "\n",
    "# Remap original labels {0,4} -> contiguous ids {0,1} for modeling\n",
    "# (Keep a copy of the original labels for reporting/debugging.)\n",
    "LABEL_MAP = {0: 0, 4: 1}\n",
    "\n",
    "for df_name, df in [(\"train\", train), (\"val\", val), (\"test\", test)]:\n",
    "    df[\"label_original\"] = df[\"label\"]\n",
    "    mapped = df[\"label_original\"].map(LABEL_MAP)\n",
    "\n",
    "    if mapped.isna().any():\n",
    "        bad = sorted(df.loc[mapped.isna(), \"label_original\"].unique().tolist())\n",
    "        raise ValueError(f\"Unexpected labels in {df_name}: {bad}\")\n",
    "\n",
    "    # Hugging Face expects targets in a column named 'label'\n",
    "    df[\"label\"] = mapped.astype(int)\n",
    "\n",
    "num_labels = train[\"label\"].nunique()\n",
    "print(\"Number of labels (label): \", num_labels)\n",
    "train.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24c957a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForSequenceClassification, BertTokenizer\n",
    "\n",
    "MODEL_NAME = \"bert-base-uncased\"\n",
    "tokenizer = BertTokenizer.from_pretrained(MODEL_NAME)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    MODEL_NAME,\n",
    "    num_labels=num_labels  \n",
    ").to(device)\n",
    "\n",
    "# To check the maximum sequence length accepted by the tokenizer/model\n",
    "max_seq_length = tokenizer.model_max_length\n",
    "print(f\"Max sequence length accepted by the tokenizer: {max_seq_length}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7b6c740",
   "metadata": {},
   "source": [
    "# Training Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8a39395",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 16\n",
    "EPOCHS = 3\n",
    "LEARNING_RATE = 2e-5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cedb5dcf",
   "metadata": {},
   "source": [
    "# Build a PyTorch Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "858ce9ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, data, tokenizer, max_seq_length):\n",
    "        self.data = data\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_seq_length = max_seq_length\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        text = str(self.data.iloc[idx][\"text of the tweet\"])\n",
    "        # Use remapped contiguous labels for modeling\n",
    "        label = self.data.iloc[idx][\"label\"]\n",
    "\n",
    "        encoding = self.tokenizer(\n",
    "            text,\n",
    "            add_special_tokens=True,\n",
    "            max_length=self.max_seq_length,\n",
    "            return_token_type_ids=False,\n",
    "            padding=\"max_length\",\n",
    "            truncation=True,\n",
    "            return_attention_mask=True,\n",
    "            return_tensors=\"pt\",\n",
    "            # return_tensors='pt' yields tensors of shape [1, max_length]\n",
    "        )\n",
    "\n",
    "        return {\n",
    "            \"text\": text,\n",
    "            \"input_ids\": encoding[\"input_ids\"].flatten(),\n",
    "            \"attention_mask\": encoding[\"attention_mask\"].flatten(),\n",
    "            \"label\": int(label),\n",
    "        }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "beb91dcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "train_dataset = CustomDataset(train, tokenizer=tokenizer, max_seq_length=max_seq_length)\n",
    "val_dataset = CustomDataset(val, tokenizer=tokenizer, max_seq_length=max_seq_length)\n",
    "test_dataset = CustomDataset(test, tokenizer=tokenizer, max_seq_length=max_seq_length)\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
    "\n",
    "# Check the shape of a single item\n",
    "sample = train_dataset[0]\n",
    "print(f\"input_ids shape: {sample['input_ids'].shape}\")  # Without flatten: [1, 512]\n",
    "\n",
    "# Check the shape after batching\n",
    "batch = next(iter(train_loader))\n",
    "print(f\"Batched input_ids shape: {batch['input_ids'].shape}\")  # Should be [16, 512], not [16, 1, 512]\n",
    "# BERT expects bs,max_seq_length\n",
    "\n",
    "# ========\n",
    "# SET UP\n",
    "# ========\n",
    "\n",
    "# Optimizer \n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=LEARNING_RATE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84cab410",
   "metadata": {},
   "outputs": [],
   "source": [
    "# With label remapping {0,4}->{0,1}, our class ids are stable\n",
    "label_0 = 0  # Negative\n",
    "label_4 = 1  # Positive\n",
    "label_0, label_4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "134669f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Estimate Training Time\n",
    "import time\n",
    "\n",
    "print(\"Estimating training time by running a few batches...\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Save model state to restore after timing\n",
    "model_state = model.state_dict().copy()\n",
    "optimizer_state = optimizer.state_dict().copy()\n",
    "\n",
    "# Warm up (first batch is usually slower)\n",
    "print(\"Warming up...\")\n",
    "model.train()\n",
    "warmup_batch = next(iter(train_loader))\n",
    "input_ids = warmup_batch['input_ids'].to(device)\n",
    "attention_mask = warmup_batch['attention_mask'].to(device)\n",
    "labels = warmup_batch['label'].to(device)\n",
    "_ = model(input_ids, attention_mask=attention_mask, labels=labels)\n",
    "\n",
    "# Time training batches\n",
    "num_test_batches = 10\n",
    "print(f\"\\nTiming {num_test_batches} training batches...\")\n",
    "start_time = time.time()\n",
    "\n",
    "for i, batch in enumerate(train_loader):\n",
    "    if i >= num_test_batches:\n",
    "        break\n",
    "    input_ids = batch['input_ids'].to(device)\n",
    "    attention_mask = batch['attention_mask'].to(device)\n",
    "    labels = batch['label'].to(device)\n",
    "    \n",
    "    optimizer.zero_grad()\n",
    "    outputs = model(input_ids, attention_mask=attention_mask, labels=labels)\n",
    "    loss = outputs.loss\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "train_time = time.time() - start_time\n",
    "avg_time_per_batch_train = train_time / num_test_batches\n",
    "\n",
    "# Time validation batches\n",
    "print(f\"Timing {num_test_batches} validation batches...\")\n",
    "model.eval()\n",
    "start_time = time.time()\n",
    "\n",
    "with torch.no_grad():\n",
    "    for i, batch in enumerate(val_loader):\n",
    "        if i >= num_test_batches:\n",
    "            break\n",
    "        input_ids = batch['input_ids'].to(device)\n",
    "        attention_mask = batch['attention_mask'].to(device)\n",
    "        labels = batch['label'].to(device)\n",
    "        outputs = model(input_ids, attention_mask=attention_mask, labels=labels)\n",
    "\n",
    "val_time = time.time() - start_time\n",
    "avg_time_per_batch_val = val_time / num_test_batches\n",
    "\n",
    "# Calculate estimates\n",
    "total_train_batches = len(train_loader)\n",
    "total_val_batches = len(val_loader)\n",
    "\n",
    "time_per_epoch_train = avg_time_per_batch_train * total_train_batches\n",
    "time_per_epoch_val = avg_time_per_batch_val * total_val_batches\n",
    "time_per_epoch_total = time_per_epoch_train + time_per_epoch_val\n",
    "total_training_time = time_per_epoch_total * EPOCHS\n",
    "\n",
    "# Convert to readable format\n",
    "def format_time(seconds):\n",
    "    hours = int(seconds // 3600)\n",
    "    minutes = int((seconds % 3600) // 60)\n",
    "    secs = int(seconds % 60)\n",
    "    if hours > 0:\n",
    "        return f\"{hours}h {minutes}m {secs}s\"\n",
    "    elif minutes > 0:\n",
    "        return f\"{minutes}m {secs}s\"\n",
    "    else:\n",
    "        return f\"{secs}s\"\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"TRAINING TIME ESTIMATE\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"Training batches per epoch: {total_train_batches:,}\")\n",
    "print(f\"Validation batches per epoch: {total_val_batches:,}\")\n",
    "print(f\"Average time per training batch: {avg_time_per_batch_train:.3f}s\")\n",
    "print(f\"Average time per validation batch: {avg_time_per_batch_val:.3f}s\")\n",
    "print(f\"\\nTime per epoch:\")\n",
    "print(f\"  Training: {format_time(time_per_epoch_train)}\")\n",
    "print(f\"  Validation: {format_time(time_per_epoch_val)}\")\n",
    "print(f\"  Total: {format_time(time_per_epoch_total)}\")\n",
    "print(f\"\\nEstimated total training time for {EPOCHS} epochs: {format_time(total_training_time)}\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Restore model and optimizer state (reset after timing test)\n",
    "print(\"\\nResetting model state after timing estimation...\")\n",
    "model.load_state_dict(model_state)\n",
    "optimizer.load_state_dict(optimizer_state)\n",
    "print(\"Ready to start training!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c12ceae",
   "metadata": {},
   "source": [
    "# Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b585736c",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_val_loss = float('inf')  # Initialize best_val_loss to a very high value\n",
    "best_epoch = -1  # Initialize best_epoch to an invalid value to track the epoch of the best validation loss\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    model.train()\n",
    "    total_train_loss = 0\n",
    "    total_val_loss = 0\n",
    "\n",
    "    # Training with progress bar\n",
    "    train_pbar = tqdm(train_loader, desc=f'Epoch {epoch + 1}/{EPOCHS} [Train]', leave=False)\n",
    "    for batch in train_pbar:\n",
    "        input_ids = batch['input_ids'].to(device)\n",
    "        attention_mask = batch['attention_mask'].to(device)\n",
    "        labels = batch['label'].to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(input_ids, attention_mask=attention_mask, labels=labels)\n",
    "        loss = outputs.loss\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_train_loss += loss.item()\n",
    "        \n",
    "        # Update progress bar with current loss\n",
    "        train_pbar.set_postfix({'loss': f'{loss.item():.4f}'})\n",
    "\n",
    "    avg_train_loss = total_train_loss / len(train_loader)\n",
    "\n",
    "    # Validation with progress bar\n",
    "    model.eval()\n",
    "    val_pbar = tqdm(val_loader, desc=f'Epoch {epoch + 1}/{EPOCHS} [Val]', leave=False)\n",
    "    with torch.no_grad():\n",
    "        for batch in val_pbar:\n",
    "            input_ids = batch['input_ids'].to(device)\n",
    "            attention_mask = batch['attention_mask'].to(device)\n",
    "            labels = batch['label'].to(device)\n",
    "\n",
    "            outputs = model(input_ids, attention_mask=attention_mask, labels=labels)\n",
    "            loss = outputs.loss\n",
    "            total_val_loss += loss.item()\n",
    "            \n",
    "            # Update progress bar with current loss\n",
    "            val_pbar.set_postfix({'loss': f'{loss.item():.4f}'})\n",
    "\n",
    "    avg_val_loss = total_val_loss / len(val_loader)\n",
    "\n",
    "    # Check if the current validation loss is the lowest; if so, save the model\n",
    "    if avg_val_loss < best_val_loss:\n",
    "        best_val_loss = avg_val_loss\n",
    "        best_epoch = epoch\n",
    "        torch.save(model.state_dict(), 'best_model.pth')  # Save the best model\n",
    "\n",
    "    print(f\"Epoch {epoch + 1}/{EPOCHS}, Training Loss: {avg_train_loss:.4f}, Validation Loss: {avg_val_loss:.4f}\")\n",
    "\n",
    "# Print the best epoch and its validation loss\n",
    "print(f\"The lowest validation loss was {best_val_loss:.4f} at epoch {best_epoch + 1}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a085863f",
   "metadata": {},
   "source": [
    "# Evaluate the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e34c841f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the best model before calculating final metrics\n",
    "model.load_state_dict(torch.load('best_model.pth'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd6a56d1",
   "metadata": {},
   "source": [
    "## Train and Validation Sets "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2251474",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "train_accuracy = calculate_accuracy(model, train_loader, device)\n",
    "train_precision = calculate_precision_recall_f1(model, train_loader, device, label_0, label_4)\n",
    "val_accuracy = calculate_accuracy(model, val_loader, device)\n",
    "val_precision = calculate_precision_recall_f1(model, val_loader, device, label_0, label_4)\n",
    "print(f\"Best Model Training Accuracy: {train_accuracy:.2f}%\")\n",
    "print(f\"Best Model Validation Accuracy: {val_accuracy:.2f}%\")\n",
    "\n",
    "# Print precision, recall, and F1 scores\n",
    "print(\"\\nTraining Metrics:\")\n",
    "print(\n",
    "    f\"  Negative (id={label_0}) - Precision: {train_precision['precision_label_0']:.4f}, \"\n",
    "    f\"Recall: {train_precision['recall_label_0']:.4f}, F1: {train_precision['f1_label_0']:.4f}\"\n",
    ")\n",
    "print(\n",
    "    f\"  Positive (id={label_4}) - Precision: {train_precision['precision_label_4']:.4f}, \"\n",
    "    f\"Recall: {train_precision['recall_label_4']:.4f}, F1: {train_precision['f1_label_4']:.4f}\"\n",
    ")\n",
    "\n",
    "print(\"\\nValidation Metrics:\")\n",
    "print(\n",
    "    f\"  Negative (id={label_0}) - Precision: {val_precision['precision_label_0']:.4f}, \"\n",
    "    f\"Recall: {val_precision['recall_label_0']:.4f}, F1: {val_precision['f1_label_0']:.4f}\"\n",
    ")\n",
    "print(\n",
    "    f\"  Positive (id={label_4}) - Precision: {val_precision['precision_label_4']:.4f}, \"\n",
    "    f\"Recall: {val_precision['recall_label_4']:.4f}, F1: {val_precision['f1_label_4']:.4f}\"\n",
    ")\n",
    "\n",
    "# Generate and plot confusion matrices\n",
    "# label is {0: Negative, 1: Positive}\n",
    "label_to_name = {0: \"Negative\", 1: \"Positive\"}\n",
    "unique_labels = [0, 1]\n",
    "class_names = [label_to_name[label] for label in unique_labels]\n",
    "\n",
    "# Confusion Matrix for Validation Set\n",
    "print(\"Validation Set Confusion Matrix:\")\n",
    "y_true_val, y_pred_val = get_confusion_matrix(model, val_loader, device)\n",
    "cm_val = plot_confusion_matrix(\n",
    "    y_true_val,\n",
    "    y_pred_val,\n",
    "    class_names,\n",
    "    title=\"Validation Set - Confusion Matrix\",\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9aaddb0a",
   "metadata": {},
   "source": [
    "## Test Sets "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb12cbbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test set metrics (same style as train/val)\n",
    "\n",
    "test_accuracy = calculate_accuracy(model, test_loader, device)\n",
    "test_precision = calculate_precision_recall_f1(model, test_loader, device, label_0, label_4)\n",
    "\n",
    "print(f\"Best Model Test Accuracy: {test_accuracy:.2f}%\")\n",
    "\n",
    "print(\"\\nTest Metrics:\")\n",
    "print(\n",
    "    f\"  Negative (id={label_0}) - Precision: {test_precision['precision_label_0']:.4f}, \"\n",
    "    f\"Recall: {test_precision['recall_label_0']:.4f}, F1: {test_precision['f1_label_0']:.4f}\"\n",
    ")\n",
    "print(\n",
    "    f\"  Positive (id={label_4}) - Precision: {test_precision['precision_label_4']:.4f}, \"\n",
    "    f\"Recall: {test_precision['recall_label_4']:.4f}, F1: {test_precision['f1_label_4']:.4f}\"\n",
    ")\n",
    "\n",
    "# Confusion Matrix for Test Set\n",
    "print(\"\\nTest Set Confusion Matrix:\")\n",
    "y_true_test, y_pred_test = get_confusion_matrix(model, test_loader, device)\n",
    "cm_test = plot_confusion_matrix(\n",
    "    y_true_test,\n",
    "    y_pred_test,\n",
    "    class_names,\n",
    "    title=\"Test Set - Confusion Matrix\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04e942d1",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
